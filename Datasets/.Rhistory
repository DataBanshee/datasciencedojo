x <- list(a=c(T, T, F, F), b=2)
x
x <- factor(c("yes", "yes", "no"))
x
x <- factor(c(TRUE, FALSE))
x
x <- factor(c(INF))
x <- factor(c(Inf))
x
x <- factor(c(0.))
x
x <- factor(c(yes))
x <- factor(c("yes"))
x <- factor(c("yes", "no", "yes", "yes"))
unclass(x)
table(x)
attr(,"levels")
attr(x,"levels")
factor(x, levels=c("no", "yes"))
m <- matrix (nrow = 2, ncol = 3)
dim(m)
attributes(m)
m
m <- matrix(1:6)
m
m <- matrix(1:6, nrow = 2, ncol = 3)
m
dim(m)
dim(m) = c(2,5)
m <- 1:10
dim(m) = c(2,5)
m
x <- 1:3
y <- 10:12
cbind(x,y)
rbind(x,y)
list(c("a", "b"), c("c", "d"))
a <- list(c("a", "b"), c("c", "d"))
m <- matrix(1:4, nrow=2, ncol=2)
dimnames(m)
m
dimnames <- a
m
score <- c(90, 79, 94, 54)
mapply(rep, c(0,2), c(3,2))
mapply(rep, c(0,2), c(3, 2))
rep
rep(2)
str(tapply)
str(lapply)
str(mapply)
install.packages('xls')
install.packages('xlsx')
library(RCurl)
x <- getURL("https://raw.githubusercontent.com/datasciencedojo/datasets/master/Titanic_train.csv")
x <- getURL("https://raw.githubusercontent.com/datasciencedojo/datasets/master/Titanic_train.csv")
library(RCURL)
install.packages(RCurl)
install.packages("RCurl")
install.packages("RCurl")
library("RCurl")
x <- getURL("https://raw.githubusercontent.com/datasciencedojo/datasets/master/Titanic_train.csv")
library("RCurl")
x <- getURL("https://raw.githubusercontent.com/datasciencedojo/datasets/master/Titanic_train.csv")
library('randomForest')
randomForest(iris)
x.trained <-randomForest(x=iris)
x.trained
help randomForest()
MDSplot(iris.urf, iris$Species)
iris.urf <- randomForest(iris[, -5])
, -5])
MDSplot(iris.urf, iris$Species)
rpart()
data(mtcars)
mtcars.rf <- randomForest(mpg ~ ., data=mtcars, ntree=1000, keep.forest=FALSE,
importance=TRUE)
plot(mtcars.rf, log="y")
varImpPlot(mtcars.rf)
data(mtcars)
mtcars.rf <- randomForest(mpg ~ ., data=mtcars, ntree=1000, keep.forest=FALSE,
importance=TRUE)
plot(mtcars.rf, log="y")
data(mtcars)
mtcars.rf <- randomForest(mpg ~ ., data=mtcars, ntree=1000, keep.forest=FALSE,
importance=TRUE)
plot(mtcars.rf, log="y")
varImpPlot(mtcars.rf)
importance(mtcars.rf)
importance(mtcars.rf)
data(mtcars)
mtcars.rf <- randomForest(mpg ~ ., data=mtcars, ntree=1000, keep.forest=FALSE,
importance=TRUE)
plot(mtcars.rf, log="y")
varImpPlot(mtcars.rf)
mtcars.rf2 <- randomForest(mtcars)
MDSplot(mtcars.rf2, mtcars$mpg)
MDSplot(mtcars.rf2)
MDSplot(mtcars.rf2, mtcars$mpg)
mtcars$mpg
MDSplot(mtcars.rf2, mtcars$mpg)
getTree(mtcars.rf)
getTree(randomForest(iris[,-5], iris[,5], ntree=10), 3, labelVar=TRUE)
q()
iris.rf <- randomForest(Species~.data=iris,importance=True)
library(randomForest)
iris.rf <- randomForest(Species~.data=iris,importance=True)
iris.rf <- randomForest(Species~.,data=iris,importance=True)
iris.rf <- randomForest(Species~.,data=iris,importance=TRUE)
importance(iris.rf)
plot(importance(iris.rf))
round(importance(iris.rf),2)
setwd("C:/GitRepos/bootcamp")
###################################################################################
## This code is part of Data Science Dojo's bootcamp
## Copyright (C) 2015
## Objective: Machine learning of Titanic data's survival classification with ensemble methods (random forest and boosted decision tree)
## Data source: Titanic data set
##              at: https://github.com/datasciencedojo/bootcamp/tree/master/Datasets
## Please install "randomForest" package: install.packages("randomForest")
###################################################################################
## load the library
library(randomForest)
## DATA EXPLORATION AND CLEANING
## load the Titanic data in R
## Be sure your working directory is set to bootcamp base directory
titanic.data <- read.csv("Datasets/titanic.csv", header=TRUE)
## explore the data set
dim(titanic.data)
str(titanic.data)
summary(titanic.data)
## remove PassengerID, Name, Ticket, and Cabin attributes
titanic.data <- titanic.data[, -c(1, 4, 9, 11)]
## Cast target attribute to factor
titanic.data$Survived <- as.factor(titanic.data$Survived)
levels(titanic.data$Survived) <- c('Dead', 'Alive')
## there are some NAs in Age, fill them with the median value
titanic.data$Age[is.na(titanic.data$Age)] = median(titanic.data$Age, na.rm=TRUE)
## BUILD MODEL
## randomly choose 70% of the data set as training data
set.seed(27)
titanic.train.indices <- sample(1:nrow(titanic.data), 0.7*nrow(titanic.data), replace=F)
titanic.train <- titanic.data[titanic.train.indices,]
dim(titanic.train)
summary(titanic.train$Survived)
## select the other 30% as the testing data
titanic.test <- titanic.data[-titanic.train.indices,]
dim(titanic.test)
summary(titanic.test$Survived)
## You could also do this
#random.rows.test <- setdiff(1:nrow(titanic.data),random.rows.train)
#titanic.test <- titanic.data[random.rows.test,]
## Fit decision model to training set
titanic.rf.model <- randomForest(Survived ~ ., data=titanic.train, importance=TRUE, ntree=500)
print(titanic.rf.model)
## MODEL EVALUATION
## Predict test set outcomes, reporting probabilities
titanic.rf.predictions <- predict(titanic.rf.model, titanic.test, type="prob")
## calculate the confusion matrix
titanic.rf.confusion <- table(titanic.rf.predictions, titanic.test$Survived)
print(titanic.rf.confusion)
## accuracy
titanic.rf.accuracy <- sum(diag(titanic.rf.confusion)) / sum(titanic.rf.confusion)
print(titanic.rf.accuracy)
## precision
titanic.rf.precision <- titanic.rf.confusion[2,2] / sum(titanic.rf.confusion[2,])
print(titanic.rf.precision)
## recall
titanic.rf.recall <- titanic.rf.confusion[2,2] / sum(titanic.rf.confusion[,2])
print(titanic.rf.recall)
## F1 score
titanic.rf.F1 <- 2 * titanic.rf.precision * titanic.rf.recall / (titanic.rf.precision + titanic.rf.recall)
print(titanic.rf.F1)
## show variable importance
importance(titanic.rf.model)
varImpPlot(titanic.rf.model)
## EXERCISE
## Random forest has built-in feature selection.
## varImpPlot() function helps us visualize the importance of the features passed to
## the model. Look at the importance table/graph, remove the least important predictor
## and re-build this model. Does it have similar performance?
## If so, iterate, removing the new least important feature and re-building the model,
## until your model has much worse performance than the original one.
## Imagine you are dealing with a much larger dataset, so memory and calculation time
## are something that you must be concerned about. In such a situation, what are the
## features you would choose to use in production?
###################################################################################
## This code is part of Data Science Dojo's bootcamp
## Copyright (C) 2015
## Objective: Machine learning of Titanic data's survival classification with ensemble methods (random forest and boosted decision tree)
## Data source: Titanic data set
##              at: https://github.com/datasciencedojo/bootcamp/tree/master/Datasets
## Please install "randomForest" package: install.packages("randomForest")
###################################################################################
## load the library
library(randomForest)
## DATA EXPLORATION AND CLEANING
## load the Titanic data in R
## Be sure your working directory is set to bootcamp base directory
titanic.data <- read.csv("Datasets/titanic.csv", header=TRUE)
## explore the data set
dim(titanic.data)
str(titanic.data)
summary(titanic.data)
## remove PassengerID, Name, Ticket, and Cabin attributes
titanic.data <- titanic.data[, -c(1, 4, 9, 11)]
## Cast target attribute to factor
titanic.data$Survived <- as.factor(titanic.data$Survived)
levels(titanic.data$Survived) <- c('Dead', 'Alive')
## there are some NAs in Age, fill them with the median value
titanic.data$Age[is.na(titanic.data$Age)] = median(titanic.data$Age, na.rm=TRUE)
## BUILD MODEL
## randomly choose 70% of the data set as training data
set.seed(27)
titanic.train.indices <- sample(1:nrow(titanic.data), 0.7*nrow(titanic.data), replace=F)
titanic.train <- titanic.data[titanic.train.indices,]
dim(titanic.train)
summary(titanic.train$Survived)
## select the other 30% as the testing data
titanic.test <- titanic.data[-titanic.train.indices,]
dim(titanic.test)
summary(titanic.test$Survived)
## You could also do this
#random.rows.test <- setdiff(1:nrow(titanic.data),random.rows.train)
#titanic.test <- titanic.data[random.rows.test,]
## Fit decision model to training set
titanic.rf.model <- randomForest(Survived ~ ., data=titanic.train, importance=TRUE, ntree=500)
print(titanic.rf.model)
## MODEL EVALUATION
## Predict test set outcomes, reporting probabilities
titanic.rf.predictions <- predict(titanic.rf.model, titanic.test, type="response")
## calculate the confusion matrix
titanic.rf.confusion <- table(titanic.rf.predictions, titanic.test$Survived)
print(titanic.rf.confusion)
## accuracy
titanic.rf.accuracy <- sum(diag(titanic.rf.confusion)) / sum(titanic.rf.confusion)
print(titanic.rf.accuracy)
## precision
titanic.rf.precision <- titanic.rf.confusion[2,2] / sum(titanic.rf.confusion[2,])
print(titanic.rf.precision)
## recall
titanic.rf.recall <- titanic.rf.confusion[2,2] / sum(titanic.rf.confusion[,2])
print(titanic.rf.recall)
## F1 score
titanic.rf.F1 <- 2 * titanic.rf.precision * titanic.rf.recall / (titanic.rf.precision + titanic.rf.recall)
print(titanic.rf.F1)
## show variable importance
importance(titanic.rf.model)
varImpPlot(titanic.rf.model)
## EXERCISE
## Random forest has built-in feature selection.
## varImpPlot() function helps us visualize the importance of the features passed to
## the model. Look at the importance table/graph, remove the least important predictor
## and re-build this model. Does it have similar performance?
## If so, iterate, removing the new least important feature and re-building the model,
## until your model has much worse performance than the original one.
## Imagine you are dealing with a much larger dataset, so memory and calculation time
## are something that you must be concerned about. In such a situation, what are the
## features you would choose to use in production?
summary(titanic.test$Survived)
summary(titanic.train$Survived)
###################################################################################
## This code is part of Data Science Dojo's bootcamp
## Copyright (C) 2015
## Objective: Machine learning of Titanic data's survival classification with ensemble methods (random forest and boosted decision tree)
## Data source: Titanic data set
##              at: https://github.com/datasciencedojo/bootcamp/tree/master/Datasets
## Please install "randomForest" package: install.packages("randomForest")
###################################################################################
## load the library
library(randomForest)
## DATA EXPLORATION AND CLEANING
## load the Titanic data in R
## Be sure your working directory is set to bootcamp base directory
titanic.data <- read.csv("Datasets/titanic.csv", header=TRUE)
## explore the data set
dim(titanic.data)
str(titanic.data)
summary(titanic.data)
## remove PassengerID, Name, Ticket, and Cabin attributes
titanic.data <- titanic.data[, -c(1, 4, 9, 11)]
## Cast target attribute to factor
titanic.data$Survived <- as.factor(titanic.data$Survived)
levels(titanic.data$Survived) <- c('Dead', 'Alive')
summary(titanic.data$Survived)
install.packages("randomForest")
library(randomForest)
titanic.data <- read.csv("titanic.csv")
setwd("~/Documents/bootcamp")
titanic.data <- read.csv("titanic.csv")
setwd("~/Documents/bootcamp/Datasets")
titanic.data <- read.csv(Titanic)
titanic.data <- read.csv("titanic.csv")
titanic.data <- titanic.data[, -c(1,4,9,11)]
titanic.data$Survived <- as.factor(titanic.data$Sex)
titanic.data$Survived <- as.factor(titanic.data$Survived)
levels(titanic.data$Survived) <- c('Dead', 'Alive')
titanic.data$Age[is.na(titanic.data$Age)] = median(titanic.data$Age, na.rm=TRUE)
set.seed(27)
titanic.train.indices <- sample(1:nrow(titanic.data), 0.7*nrow(titanic.data), replace=F)
titanic.train <- titanic.data[titanic.train.indices,]
dim(titanic.train)
summary(titanic.train$Survived)
titanic.test <- titanic.data[-titanic.train.indices,]
dim(titanic.test)
summary(titanic.test$Survived)
titanic.rf.model <- randomForest(Survived ~ ., data=titanic.train, importance=TRUE, ntree=500)
print(titanic.rf.model)
titanic.rf.model <- randomForest(Survived ~ ., data=titanic.train, importance=TRUE, ntree=500)
print(titanic.rf.model)
titanic.rf.predictions <- predict(titanic.rf.model, titanic.test, type="prob")
titanic.rf.confusion <- table(titanic.rf.predictions, titanic.test$Survived)
titanic.rf.confusion <- table(titanic.rf.predictions, titanic.test$Survived)
print(titanic.rf.confusion)
titanic.train.indices <- sample(1:nrow(titanic.data), 0.7*nrow(titanic.data), replace=F)
titanic.train <- titanic.data[titanic.train.indices,]
dim(titanic.train)
summary(titanic.train$Survived)
titanic.test <- titanic.data[-titanic.train.indices,]
dim(titanic.test)
summary(titanic.test$Survived)
titanic.rf.model <- randomForest(Survived ~ ., data=titanic.train, importance=TRUE, ntree=500)
print(titanic.rf.model)
titanic.rf.predictions <- predict(titanic.rf.model, titanic.test, type="prob")
titanic.rf.confusion <- table(titanic.rf.predictions, titanic.test$Survived)
print(titanic.rf.confusion)
titanic.rf.predictions <- predict(titanic.rf.model, titanic.test, type="response")
print(titanic.rf.confusion)
titanic.rf.confusion <- table(titanic.rf.predictions, titanic.test$Survived)
print(titanic.rf.confusion)
importance(titanic.rf.model)
varImpPlot(titanic.rf.model)
?randomForest
str(titanic)
head(titanic.data)
?read.csv
head(titanic.data)
head(titanic.train)
#install.packages("randomForest")
library(randomForest)
titanic.data <- read.csv("titanic.csv")
titanic.data <- titanic.data[, -c(1,4,9,11)]
titanic.data$Survived <- as.factor(titanic.data$Sex)
titanic.data$Survived <- as.factor(titanic.data$Survived)
levels(titanic.data$Survived) <- c('Dead', 'Alive')
titanic.data$Age[is.na(titanic.data$Age)] = median(titanic.data$Age, na.rm=TRUE)
set.seed(27)
titanic.train.indices <- sample(1:nrow(titanic.data), 0.7*nrow(titanic.data), replace=F)
titanic.train <- titanic.data[titanic.train.indices,]
dim(titanic.train)
summary(titanic.train$Survived)
titanic.test <- titanic.data[-titanic.train.indices,]
dim(titanic.test)
summary(titanic.test$Survived)
titanic.rf.model <- randomForest(Survived ~ ., data=titanic.train, importance=TRUE, ntree=500)
print(titanic.rf.model)
titanic.rf.model <- randomForest(Survived ~ ., data=titanic.train, importance=TRUE, ntree=500)
print(titanic.rf.model)
titanic.rf.predictions <- predict(titanic.rf.model, titanic.test, type="prob")
titanic.rf.confusion <- table(titanic.rf.predictions, titanic.test$Survived)
titanic.rf.confusion <- table(titanic.rf.predictions, titanic.test$Survived)
print(titanic.rf.confusion)
titanic.train.indices <- sample(1:nrow(titanic.data), 0.7*nrow(titanic.data), replace=F)
titanic.train <- titanic.data[titanic.train.indices,]
dim(titanic.train)
summary(titanic.train$Survived)
titanic.test <- titanic.data[-titanic.train.indices,]
dim(titanic.test)
summary(titanic.test$Survived)
titanic.rf.model <- randomForest(Survived ~ ., data=titanic.train, importance=TRUE, ntree=500)
print(titanic.rf.model)
titanic.rf.predictions <- predict(titanic.rf.model, titanic.test, type="prob")
titanic.rf.confusion <- table(titanic.rf.predictions, titanic.test$Survived)
print(titanic.rf.confusion)
titanic.rf.predictions <- predict(titanic.rf.model, titanic.test, type="response")
print(titanic.rf.confusion)
titanic.rf.confusion <- table(titanic.rf.predictions, titanic.test$Survived)
print(titanic.rf.confusion)
importance(titanic.rf.model)
varImpPlot(titanic.rf.model)
?randomForest
str(titanic)
head(titanic.data)
?read.csv
head(titanic.data)
head(titanic.train)
#install.packages("randomForest")
library(randomForest)
titanic.data <- read.csv("titanic.csv")
titanic.data <- titanic.data[, -c(1,4,9,11)]
setwd("C:/GitRepos/bootcamp/Datasets")
#install.packages("randomForest")
library(randomForest)
titanic.data <- read.csv("titanic.csv")
titanic.data <- titanic.data[, -c(1,4,9,11)]
titanic.data$Survived <- as.factor(titanic.data$Sex)
titanic.data$Survived <- as.factor(titanic.data$Survived)
levels(titanic.data$Survived) <- c('Dead', 'Alive')
summary((titanic.data$Survived)
)
#install.packages("randomForest")
library(randomForest)
titanic.data <- read.csv("titanic.csv", header=TRUE)
titanic.data <- titanic.data[, -c(1,4,9,11)]
titanic.data$Survived <- as.factor(titanic.data$Sex)
titanic.data$Survived <- as.factor(titanic.data$Survived)
levels(titanic.data$Survived) <- c('Dead', 'Alive')
titanic.data$Age[is.na(titanic.data$Age)] = median(titanic.data$Age, na.rm=TRUE)
set.seed(27)
titanic.train.indices <- sample(1:nrow(titanic.data), 0.7*nrow(titanic.data), replace=F)
titanic.train <- titanic.data[titanic.train.indices,]
dim(titanic.train)
summary(titanic.train$Survived)
titanic.test <- titanic.data[-titanic.train.indices,]
dim(titanic.test)
summary(titanic.test$Survived)
titanic.rf.model <- randomForest(Survived ~ ., data=titanic.train, importance=TRUE, ntree=500)
print(titanic.rf.model)
titanic.rf.model <- randomForest(Survived ~ ., data=titanic.train, importance=TRUE, ntree=500)
print(titanic.rf.model)
titanic.rf.predictions <- predict(titanic.rf.model, titanic.test, type="prob")
titanic.rf.confusion <- table(titanic.rf.predictions, titanic.test$Survived)
titanic.rf.confusion <- table(titanic.rf.predictions, titanic.test$Survived)
print(titanic.rf.confusion)
titanic.train.indices <- sample(1:nrow(titanic.data), 0.7*nrow(titanic.data), replace=F)
titanic.train <- titanic.data[titanic.train.indices,]
dim(titanic.train)
summary(titanic.train$Survived)
titanic.test <- titanic.data[-titanic.train.indices,]
dim(titanic.test)
summary(titanic.test$Survived)
titanic.rf.model <- randomForest(Survived ~ ., data=titanic.train, importance=TRUE, ntree=500)
print(titanic.rf.model)
titanic.rf.predictions <- predict(titanic.rf.model, titanic.test, type="prob")
titanic.rf.confusion <- table(titanic.rf.predictions, titanic.test$Survived)
print(titanic.rf.confusion)
titanic.rf.predictions <- predict(titanic.rf.model, titanic.test, type="response")
print(titanic.rf.confusion)
titanic.rf.confusion <- table(titanic.rf.predictions, titanic.test$Survived)
print(titanic.rf.confusion)
importance(titanic.rf.model)
varImpPlot(titanic.rf.model)
?randomForest
str(titanic)
head(titanic.data)
?read.csv
head(titanic.data)
head(titanic.train)
#install.packages("randomForest")
library(randomForest)
titanic.data <- read.csv("titanic.csv", header=TRUE)
titanic.data <- titanic.data[, -c(1,4,9,11)]
titanic.data$Survived <- as.factor(titanic.data$Sex)
titanic.data$Survived <- as.factor(titanic.data$Survived)
levels(titanic.data$Survived) <- c('Dead', 'Alive')
summary(titanic.data$Survived)
###################################################################################
## This code is part of Data Science Dojo's bootcamp
## Copyright (C) 2015
## Objective: Machine learning of Titanic data's survival classification with ensemble methods (random forest and boosted decision tree)
## Data source: Titanic data set
##              at: https://github.com/datasciencedojo/bootcamp/tree/master/Datasets
## Please install "randomForest" package: install.packages("randomForest")
###################################################################################
## load the library
library(randomForest)
## DATA EXPLORATION AND CLEANING
## load the Titanic data in R
## Be sure your working directory is set to bootcamp base directory
titanic.data <- read.csv("Datasets/titanic.csv", header=TRUE)
## explore the data set
dim(titanic.data)
str(titanic.data)
summary(titanic.data)
## remove PassengerID, Name, Ticket, and Cabin attributes
titanic.data <- titanic.data[, -c(1, 4, 9, 11)]
## Cast target attribute to factor
titanic.data$Survived <- as.factor(titanic.data$Survived)
levels(titanic.data$Survived) <- c('Dead', 'Alive')
summary(titanic.data$Survived)
###################################################################################
## This code is part of Data Science Dojo's bootcamp
## Copyright (C) 2015
## Objective: Machine learning of Titanic data's survival classification with ensemble methods (random forest and boosted decision tree)
## Data source: Titanic data set
##              at: https://github.com/datasciencedojo/bootcamp/tree/master/Datasets
## Please install "randomForest" package: install.packages("randomForest")
###################################################################################
## load the library
library(randomForest)
## DATA EXPLORATION AND CLEANING
## load the Titanic data in R
## Be sure your working directory is set to bootcamp base directory
titanic.data <- read.csv("titanic.csv", header=TRUE)
## explore the data set
dim(titanic.data)
str(titanic.data)
summary(titanic.data)
## remove PassengerID, Name, Ticket, and Cabin attributes
titanic.data <- titanic.data[, -c(1, 4, 9, 11)]
## Cast target attribute to factor
titanic.data$Survived <- as.factor(titanic.data$Survived)
levels(titanic.data$Survived) <- c('Dead', 'Alive')
summary(titanic.data$Survived)
#install.packages("randomForest")
library(randomForest)
titanic.data <- read.csv("titanic.csv", header=TRUE)
titanic.data <- titanic.data[, -c(1,4,9,11)]
titanic.data$Survived <- as.factor(titanic.data$Sex)
titanic.data$Survived <- as.factor(titanic.data$Survived)
levels(titanic.data$Survived) <- c('Dead', 'Alive')
summary(titanic.data$Survived)
